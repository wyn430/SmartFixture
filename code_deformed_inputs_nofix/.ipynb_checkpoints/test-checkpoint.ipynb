{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinanw/anaconda3/envs/torch-new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from ansys.mapdl.core import launch_mapdl, launcher, Mapdl\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from Ansys_env import Env\n",
    "\n",
    "from PPO_test import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "training environment name : Ansys_assembly\n",
      "load the model from : PPO_preTrained/Ansys_assembly//deformed_inputs_nofix_metal_pretrained.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_timestamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 277\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m============================================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 126\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload the model from : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m checkpoint_path)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#####################################################\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#### create new log file for this test\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m log_f_name \u001b[38;5;241m=\u001b[39m log_dir \u001b[38;5;241m+\u001b[39m \u001b[43mcheckpoint_timestamp\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPPO_test_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m checkpoint_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent logging run number for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m, checkpoint_name)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogging at : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m log_f_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_timestamp' is not defined"
     ]
    }
   ],
   "source": [
    "################################### Training ###################################\n",
    "\n",
    "def test():\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "    \n",
    "    \n",
    "    ################################## set device ##################################\n",
    "\n",
    "    # set device to cpu or cuda\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    if(torch.cuda.is_available()): \n",
    "        device = torch.device('cuda') \n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "    else:\n",
    "        print(\"Device set to : cpu\")\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "    ####### initialize environment hyperparameters ######\n",
    "\n",
    "    env_name = \"Ansys_assembly\"\n",
    "\n",
    "    quant_lim = 8\n",
    "    max_ep_len = 20                   # max timesteps in one episode\n",
    "    max_training_timesteps = int(100)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "    print_freq = max_ep_len        # print avg reward in the interval (in num timesteps)\n",
    "    log_freq = max_ep_len           # log avg reward in the interval (in num timesteps)\n",
    "    save_model_freq = int(max_ep_len)          # save model frequency (in num timesteps)\n",
    "    thresh = 0.42 ##controls the minimum distance between two fixtures\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    data_dir = '../Deformed_inputs_2mm/'\n",
    "    train_file_list = np.load('train_file_list.npy')\n",
    "    test_file_list = np.load('test_file_list.npy')\n",
    "    original_input_filename = data_dir + 'input_step1.inp' ##use the step1 input to initialize for the bottom surface nodes\n",
    "    initial_deform_file = data_dir + 'deform_step1_dp1.npz' ##only use to initialize\n",
    "    initial_deform = np.load(initial_deform_file)['data']\n",
    "    initial_fixture_locations = [2552,2578,2628]\n",
    "    #########################\n",
    "    \n",
    "    max_num = 100\n",
    "    ip = '45.3.127.119'\n",
    "    port = 8800\n",
    "    \n",
    "    print(\"training environment name : \" + env_name)\n",
    "    \n",
    "\n",
    "    #####################################################\n",
    "\n",
    "\n",
    "    ## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "    ################ PPO hyperparameters ################\n",
    "\n",
    "    update_timestep = max_ep_len      # update policy every n timesteps\n",
    "    K_epochs = 20               # update policy for K epochs in one PPO update\n",
    "    train_batch = 5\n",
    "    \n",
    "    eps_clip = 0.2          # clip parameter for PPO\n",
    "    gamma = 0.99            # discount factor\n",
    "\n",
    "    lr_actor = 0.0003       # learning rate for actor network\n",
    "    lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "    random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "    ############### Network Hyperparameters #############\n",
    "    \n",
    "    shared_channel_list = [1, 8, 16, 16] #this may not be used when the shared module is GCN\n",
    "    #actor_arm_dim_list = [256, 128, 64]\n",
    "    #critic_arm_dim_list = [512, 128, 64]\n",
    "    actor_arm_dim_list = [1024, 512, 256]\n",
    "    critic_arm_dim_list = [512, 128, 64]\n",
    "    emb_dims = 512\n",
    "    feature_dims = 3\n",
    "    k = 8\n",
    "\n",
    "\n",
    "    ###################### logging ######################\n",
    "\n",
    "    #### log files for multiple runs are NOT overwritten\n",
    "    checkpoint_timestamp = 'deformed_inputs_nofix_metal'\n",
    "    \n",
    "    log_dir = \"PPO_logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "          os.makedirs(log_dir)\n",
    "\n",
    "    log_dir = log_dir + '/' + env_name + '/'\n",
    "    if not os.path.exists(log_dir):\n",
    "          os.makedirs(log_dir)\n",
    "\n",
    "    input_filename = log_dir + original_input_filename.split('/')[-1]\n",
    "    copyfile(original_input_filename, input_filename)\n",
    "\n",
    "\n",
    "    ################### checkpointing ###################\n",
    "\n",
    "    run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "    directory = \"PPO_preTrained\"\n",
    "    if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "\n",
    "    directory = directory + '/' + env_name + '/'\n",
    "    if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "    \n",
    "    \n",
    "    checkpoint_name = \"deformed_inputs_nofix_metal_pretrained\"\n",
    "    checkpoint_path = directory + checkpoint_timestamp + '/' + checkpoint_name + \".pth\"\n",
    "    print(\"load the model from : \" + checkpoint_path)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "\n",
    "\n",
    "    #### create new log file for this test\n",
    "    log_f_name = log_dir + checkpoint_timestamp + '/' + 'PPO_test_' + checkpoint_name + \".txt\"\n",
    "\n",
    "    print(\"current logging run number for \" + env_name + \" : \", checkpoint_name)\n",
    "    print(\"logging at : \" + log_f_name)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "    print(\"initialize environment\")\n",
    "    \n",
    "    env = Env(original_input_filename, input_filename, initial_fixture_locations, max_ep_len, thresh, ip, port, initial_deform)\n",
    "\n",
    "    # state space dimension\n",
    "    state_dim = env.get_state_shape()\n",
    "\n",
    "    # action space dimension\n",
    "    \n",
    "    action2_dim = env.get_action_shape()\n",
    "\n",
    "\n",
    "    ############# print all hyperparameters #############\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"max training timesteps : \", max_training_timesteps)\n",
    "    print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"state space dimension : \", state_dim)\n",
    "    \n",
    "    print(\"action2 space dimension : \", action2_dim)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "    if random_seed:\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        print(\"setting random seed to \", random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        env.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "    ################# training procedure ################\n",
    "\n",
    "    # initialize a PPO agent\n",
    "    ppo_agent = PPO(state_dim, action2_dim, shared_channel_list, actor_arm_dim_list, critic_arm_dim_list, \n",
    "                    emb_dims, feature_dims, k, lr_actor, lr_critic, gamma, K_epochs, \n",
    "                    eps_clip, device, checkpoint_path)\n",
    "\n",
    "\n",
    "    # track total training time\n",
    "    start_time = datetime.now().replace(microsecond=0)\n",
    "    print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "    # logging file\n",
    "    log_f = open(log_f_name,\"w+\")\n",
    "    log_f.write('action2,timestep,reward\\n')\n",
    "\n",
    "\n",
    "    # printing and logging variables\n",
    "    print_running_reward = 0\n",
    "    print_running_episodes = 0\n",
    "\n",
    "    log_running_reward = 0\n",
    "    log_running_episodes = 0\n",
    "\n",
    "    time_step = 0\n",
    "    i_episode = 0\n",
    "    idx = 0\n",
    "\n",
    "    # training loop\n",
    "    while time_step <= max_training_timesteps:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        original_input_filename = test_file_list[idx]\n",
    "        design_point = original_input_filename.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "        initial_deform_file = data_dir + 'deform_step1_' + design_point + '.npz'\n",
    "        initial_deform = np.load(initial_deform_file)['data']\n",
    "        input_filename = log_dir + checkpoint_timestamp + '/' + 'test_input/' + original_input_filename.split('/')[-1]\n",
    "        copyfile(original_input_filename, input_filename)\n",
    "        print('current using ' + original_input_filename.split('/')[-1])\n",
    "        \n",
    "        x, state, mask = env.reset(initial_fixture_locations, original_input_filename, input_filename, initial_deform.copy())\n",
    "        #print(state.shape)\n",
    "        current_ep_reward = 0\n",
    "        idx += 1\n",
    "\n",
    "        for t in tqdm(range(1, max_ep_len+1)):\n",
    "\n",
    "            # select action with policy\n",
    "            action2 = ppo_agent.select_action(x, state, mask)\n",
    "            #print(action2)\n",
    "            \n",
    "            x, state, reward, done, mask = env.step(action2, original_input_filename, input_filename, quant_lim, initial_deform.copy())\n",
    "            print(t)\n",
    "            print(np.linalg.norm(state[0,:,:3], axis = 1).max())\n",
    "            #print(np.linalg.norm(state[0,:,3:6], axis = 1).max())\n",
    "            print(reward)\n",
    "            #print(done)\n",
    "            # saving reward and is_terminals\n",
    "            ppo_agent.buffer.rewards.append(reward)\n",
    "            ppo_agent.buffer.is_terminals.append(done)\n",
    "\n",
    "            time_step +=1\n",
    "            current_ep_reward += reward\n",
    "\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(action2, time_step, reward))\n",
    "            log_f.flush()\n",
    "\n",
    "\n",
    "\n",
    "            # break; if the episode is over\n",
    "            if done:\n",
    "                print('done')\n",
    "                break\n",
    "                \n",
    "        if idx >= 5:\n",
    "            break\n",
    "\n",
    "        \n",
    "    log_f.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print total training time\n",
    "    print(\"============================================================================================\")\n",
    "    end_time = datetime.now().replace(microsecond=0)\n",
    "    print(\"Started testing at (GMT) : \", start_time)\n",
    "    print(\"Finished testing at (GMT) : \", end_time)\n",
    "    print(\"Total training time  : \", end_time - start_time)\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-new",
   "language": "python",
   "name": "torch-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
