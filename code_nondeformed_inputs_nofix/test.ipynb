{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinanw/anaconda3/envs/torch-new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from ansys.mapdl.core import launch_mapdl, launcher, Mapdl\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from Ansys_env import Env\n",
    "\n",
    "from PPO_test import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "training environment name : Ansys_assembly\n",
      "load the model from : PPO_preTrained/Ansys_assembly/nondeformed_inputs_nofix_metal/nondeformed_inputs_nofix_metal_pretrained.pth\n",
      "current logging run number for Ansys_assembly :  nondeformed_inputs_nofix_metal_pretrained\n",
      "logging at : PPO_logs/Ansys_assembly/nondeformed_inputs_nofix_metal/PPO_test_nondeformed_inputs_nofix_metal_pretrained.txt\n",
      "initialize environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinanw/anaconda3/envs/torch-new/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  1\n",
      "max timesteps per episode :  20\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  (3901, 3)\n",
      "action2 space dimension :  3901\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a discrete action space policy\n",
      "============================================================================================\n",
      "Let's use 0 GPUs!\n",
      "Started training at (GMT) :  2024-08-31 21:36:07\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██▏                                         | 1/20 [00:02<00:42,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▍                                       | 2/20 [00:04<00:38,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████▌                                     | 3/20 [00:06<00:39,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.1934556370829018\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████▊                                   | 4/20 [00:09<00:38,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.03065909188502449\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████                                 | 5/20 [00:12<00:37,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.019197655670755102\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████▏                              | 6/20 [00:14<00:35,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.011021893287032172\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▍                            | 7/20 [00:17<00:33,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0.0035239455091479873\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███████████████▍                            | 7/20 [00:19<00:36,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0.0021893550964201527\n",
      "0.2659683793521705\n",
      "done\n",
      "============================================================================================\n",
      "Started testing at (GMT) :  2024-08-31 21:36:07\n",
      "Finished testing at (GMT) :  2024-08-31 21:36:30\n",
      "Total training time  :  0:00:23\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "################################### Training ###################################\n",
    "\n",
    "def test():\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "    \n",
    "    \n",
    "    ################################## set device ##################################\n",
    "\n",
    "    # set device to cpu or cuda\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    if(torch.cuda.is_available()): \n",
    "        device = torch.device('cuda') \n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "    else:\n",
    "        print(\"Device set to : cpu\")\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "    ####### initialize environment hyperparameters ######\n",
    "\n",
    "    env_name = \"Ansys_assembly\"\n",
    "\n",
    "    quant_lim = 8\n",
    "    max_ep_len = 20                   # max timesteps in one episode\n",
    "    max_training_timesteps = int(1)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "    print_freq = max_ep_len        # print avg reward in the interval (in num timesteps)\n",
    "    log_freq = max_ep_len           # log avg reward in the interval (in num timesteps)\n",
    "    save_model_freq = int(max_ep_len)          # save model frequency (in num timesteps)\n",
    "    thresh = 0.45 ##controls the minimum distance between two fixtures\n",
    "    \n",
    "    original_input_filename = 'input_nondeform_2mm.inp'\n",
    "    initial_fixture_locations = [2552, 2578, 2628]\n",
    "    max_num = 20\n",
    "    ip = '45.3.127.119'\n",
    "    port = 8800\n",
    "    \n",
    "    print(\"training environment name : \" + env_name)\n",
    "    \n",
    "\n",
    "    #####################################################\n",
    "\n",
    "\n",
    "    ## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "    ################ PPO hyperparameters ################\n",
    "\n",
    "    update_timestep = max_ep_len      # update policy every n timesteps\n",
    "    K_epochs = 20               # update policy for K epochs in one PPO update\n",
    "    train_batch = 5\n",
    "    \n",
    "    eps_clip = 0.2          # clip parameter for PPO\n",
    "    gamma = 0.99            # discount factor\n",
    "\n",
    "    lr_actor = 0.0003       # learning rate for actor network\n",
    "    lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "    random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "    ############### Network Hyperparameters #############\n",
    "    \n",
    "    shared_channel_list = [1, 8, 16, 16] #this may not be used when the shared module is GCN\n",
    "    #actor_arm_dim_list = [256, 128, 64]\n",
    "    #critic_arm_dim_list = [512, 128, 64]\n",
    "    actor_arm_dim_list = [1024, 512, 256]\n",
    "    critic_arm_dim_list = [512, 128, 64]\n",
    "    emb_dims = 512\n",
    "    feature_dims = 6\n",
    "    k = 8\n",
    "\n",
    "\n",
    "    ###################### logging ######################\n",
    "\n",
    "    #### log files for multiple runs are NOT overwritten\n",
    "    checkpoint_timestamp = 'nondeformed_inputs_nofix_metal'\n",
    "    \n",
    "    log_dir = \"PPO_logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "          os.makedirs(log_dir)\n",
    "\n",
    "    log_dir = log_dir + '/' + env_name + '/'\n",
    "    if not os.path.exists(log_dir):\n",
    "          os.makedirs(log_dir)\n",
    "\n",
    "    input_filename = log_dir + checkpoint_timestamp + '/' + original_input_filename\n",
    "    copyfile(original_input_filename, input_filename)\n",
    "\n",
    "\n",
    "    ################### checkpointing ###################\n",
    "\n",
    "    run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "    directory = \"PPO_preTrained\"\n",
    "    if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "\n",
    "    directory = directory + '/' + env_name + '/'\n",
    "    if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "    \n",
    "    \n",
    "    checkpoint_name = \"nondeformed_inputs_nofix_metal_pretrained\"\n",
    "    checkpoint_path = directory + checkpoint_timestamp + '/' + checkpoint_name + \".pth\"\n",
    "    print(\"load the model from : \" + checkpoint_path)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "\n",
    "\n",
    "    #### create new log file for this test\n",
    "    log_f_name = log_dir + checkpoint_timestamp + '/' + 'PPO_test_' + checkpoint_name + \".txt\"\n",
    "\n",
    "    print(\"current logging run number for \" + env_name + \" : \", checkpoint_name)\n",
    "    print(\"logging at : \" + log_f_name)\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "    print(\"initialize environment\")\n",
    "    \n",
    "    env = Env(original_input_filename, input_filename, initial_fixture_locations, max_ep_len, thresh, ip, port)\n",
    "\n",
    "    # state space dimension\n",
    "    state_dim = env.get_state_shape()\n",
    "\n",
    "    # action space dimension\n",
    "    \n",
    "    action2_dim = env.get_action_shape()\n",
    "\n",
    "\n",
    "    ############# print all hyperparameters #############\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"max training timesteps : \", max_training_timesteps)\n",
    "    print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"state space dimension : \", state_dim)\n",
    "    \n",
    "    print(\"action2 space dimension : \", action2_dim)\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "    if random_seed:\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        print(\"setting random seed to \", random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        env.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    #####################################################\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "    ################# training procedure ################\n",
    "\n",
    "    # initialize a PPO agent\n",
    "    ppo_agent = PPO(state_dim, action2_dim, shared_channel_list, actor_arm_dim_list, critic_arm_dim_list, \n",
    "                    emb_dims, feature_dims, k, lr_actor, lr_critic, gamma, K_epochs, eps_clip, device, checkpoint_path)\n",
    "\n",
    "\n",
    "    # track total training time\n",
    "    start_time = datetime.now().replace(microsecond=0)\n",
    "    print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "    # logging file\n",
    "    log_f = open(log_f_name,\"w+\")\n",
    "    log_f.write('action2,timestep,reward\\n')\n",
    "\n",
    "\n",
    "    # printing and logging variables\n",
    "    print_running_reward = 0\n",
    "    print_running_episodes = 0\n",
    "\n",
    "    log_running_reward = 0\n",
    "    log_running_episodes = 0\n",
    "\n",
    "    time_step = 0\n",
    "    i_episode = 0\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    while time_step <= max_training_timesteps:\n",
    "        \n",
    "        \n",
    "        x, state, mask = env.reset(initial_fixture_locations, original_input_filename, input_filename)\n",
    "        #print(mask.shape)\n",
    "        current_ep_reward = 0\n",
    "        \n",
    "        #print(np.linalg.norm(state[0,:,:3], axis = 1).max())\n",
    "        #print(np.linalg.norm(state[0,:,3:6], axis = 1).max())\n",
    "        #for t in tqdm(range(1, max_ep_len+1)):\n",
    "        for t in tqdm(range(1, max_ep_len+1)):\n",
    "\n",
    "            # select action with policy\n",
    "            action2 = ppo_agent.select_action(x, state, mask)\n",
    "            \n",
    "            x, state, reward, done, mask = env.step(action2, original_input_filename, input_filename, quant_lim)\n",
    "            print(t)\n",
    "            print(np.linalg.norm(state[0,:,:3], axis = 1).max())\n",
    "            #print(np.linalg.norm(state[0,:,3:6], axis = 1).max())\n",
    "            print(reward)\n",
    "            #print(done)\n",
    "            # saving reward and is_terminals\n",
    "            ppo_agent.buffer.rewards.append(reward)\n",
    "            ppo_agent.buffer.is_terminals.append(done)\n",
    "\n",
    "            time_step +=1\n",
    "            current_ep_reward += reward\n",
    "\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(action2, time_step, reward))\n",
    "            log_f.flush()\n",
    "\n",
    "\n",
    "\n",
    "            # break; if the episode is over\n",
    "            if done:\n",
    "                print('done')\n",
    "                break\n",
    "\n",
    "        \n",
    "    log_f.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print total training time\n",
    "    print(\"============================================================================================\")\n",
    "    end_time = datetime.now().replace(microsecond=0)\n",
    "    print(\"Started testing at (GMT) : \", start_time)\n",
    "    print(\"Finished testing at (GMT) : \", end_time)\n",
    "    print(\"Total training time  : \", end_time - start_time)\n",
    "    print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-new",
   "language": "python",
   "name": "torch-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
